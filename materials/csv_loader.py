# -*- coding: utf-8 -*-
import pandas as pd
import os
from django.conf import settings
from .models import Material
from decimal import Decimal
import logging
from django.db import transaction
import chardet
import re

logger = logging.getLogger(__name__)


class MaterialCSVLoader:
    def __init__(self):
        self.data_dir = os.path.join(settings.BASE_DIR, 'data')
        self.csv_file = 'åŸæ–™ãƒã‚¹ã‚¿è©³ç´°.csv'

    def detect_encoding_comprehensive(self, file_path):
        """åŒ…æ‹¬çš„ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡º"""
        encodings_to_try = [
            'cp932',  # Shift_JIS (Windows) - æ—¥æœ¬èªã§æœ€ã‚‚ä¸€èˆ¬çš„
            'shift_jis',  # Shift_JIS
            'utf-8',  # UTF-8
            'utf-8-sig',  # UTF-8 with BOM
            'iso-2022-jp',  # JIS
            'euc-jp',  # EUC-JP
            'latin1',  # ISO-8859-1
        ]

        # chardetã«ã‚ˆã‚‹è‡ªå‹•æ¤œå‡º
        try:
            with open(file_path, 'rb') as f:
                raw_data = f.read(50000)
                detected = chardet.detect(raw_data)
                if detected['encoding'] and detected['confidence'] > 0.5:
                    detected_encoding = detected['encoding']
                    if detected_encoding not in encodings_to_try:
                        encodings_to_try.insert(0, detected_encoding)
                    print(f"ğŸ” chardetæ¤œå‡º: {detected_encoding} (ä¿¡é ¼åº¦: {detected['confidence']:.2f})")
        except Exception as e:
            print(f"âš ï¸ chardetæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")

        return encodings_to_try

    def create_flexible_column_mapping(self, columns):
        """å®Ÿéš›ã®åˆ—åã«åŸºã¥ã„ã¦æŸ”è»Ÿãªåˆ—ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ"""
        print(f"ğŸ”— å®Ÿéš›ã®åˆ—å: {columns}")

        # åˆ—åãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°è¾æ›¸
        patterns = {
            'material_id': ['åŸæ–™ID', 'ï¼©ï¼¤', 'ID', 'id', 'CD', 'cd', 'å“ç•ª', 'ã‚³ãƒ¼ãƒ‰'],
            'material_name': ['åŸæ–™å', 'åå‰', 'å•†å“å', 'å“å', 'name', 'è£½å“å', 'åç§°'],
            'manufacturer': ['è£½é€ æ‰€', 'ãƒ¡ãƒ¼ã‚«ãƒ¼', 'ãƒ¡ãƒ¼ã‚«', 'è£½é€ è€…', 'è£½é€ å…ƒ', 'maker', 'manufacturer'],
            'supplier': ['è²©å£²è€…', 'ç™ºæ³¨å…ˆ', 'ä¾›çµ¦å…ƒ', 'ä¾›çµ¦å…ˆ', 'ä»•å…¥å…ˆ', 'supplier', 'æ¥­è€…'],
            'application': ['è·å§¿', 'é©ç”¨', 'ç”¨é€”', 'ä½¿ç”¨ç”¨é€”', 'ç›®çš„', 'application'],
            'unit_price': ['å˜ä¾¡', 'ä¾¡æ ¼', 'å€¤æ®µ', 'price', 'é‡‘é¡', 'å˜ä½ä¾¡æ ¼'],
            'order_quantity': ['æ­£è¢‹é‡é‡', 'ç™ºæ³¨é‡', 'æ³¨æ–‡é‡', 'è³¼å…¥é‡', 'quantity', 'æ•°é‡', 'é‡é‡'],
            'remarks': ['å‚™è€ƒ', 'å“è³ªç®¡ç†å‚™è€ƒ', 'æ³¨è¨˜', 'ãƒ¡ãƒ¢', 'èª¬æ˜', 'remarks', 'memo'],
            'material_category': ['åŸæ–™åŒºåˆ†', 'åŒºåˆ†', 'åˆ†é¡', 'ã‚«ãƒ†ã‚´ãƒª', 'category', 'ç¨®é¡']
        }

        mapping = {}
        used_columns = set()

        for field, pattern_list in patterns.items():
            for col in columns:
                if col not in used_columns:
                    col_clean = str(col).strip()
                    for pattern in pattern_list:
                        if pattern in col_clean or col_clean in pattern:
                            mapping[field] = col
                            used_columns.add(col)
                            print(f"âœ… ãƒãƒƒãƒ”ãƒ³ã‚°: {field} â† '{col}'")
                            break
                    if field in mapping:
                        break

            if field not in mapping:
                print(f"âš ï¸ ãƒãƒƒãƒ”ãƒ³ã‚°å¤±æ•—: {field}")

        return mapping

    def load_materials(self):
        """åŸæ–™CSVãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆæŸ”è»Ÿæ€§ã‚’å‘ä¸Šï¼‰"""
        try:
            file_path = os.path.join(self.data_dir, self.csv_file)

            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            if not os.path.exists(file_path):
                # ä»–ã®å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«åã‚‚è©¦è¡Œ
                possible_files = [
                    'åŸæ–™ãƒã‚¹ã‚¿è©³ç´°.csv',
                    'material_master.csv',
                    'genryou_master.csv',
                    'materials.csv'
                ]

                found_file = None
                for filename in possible_files:
                    test_path = os.path.join(self.data_dir, filename)
                    if os.path.exists(test_path):
                        found_file = test_path
                        print(f"ğŸ“„ ä»£æ›¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹: {filename}")
                        break

                if found_file:
                    file_path = found_file
                else:
                    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
                    if os.path.exists(self.data_dir):
                        csv_files = [f for f in os.listdir(self.data_dir) if f.endswith('.csv')]
                        if csv_files:
                            print(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªCSVãƒ•ã‚¡ã‚¤ãƒ«: {csv_files}")
                            # æœ€åˆã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
                            file_path = os.path.join(self.data_dir, csv_files[0])
                            print(f"ğŸ“„ è‡ªå‹•é¸æŠ: {csv_files[0]}")
                        else:
                            raise FileNotFoundError(f"dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.data_dir}")
                    else:
                        raise FileNotFoundError(f"dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.data_dir}")

            print(f"ğŸ“– èª­ã¿è¾¼ã¿å¯¾è±¡: {file_path}")

            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºã¨èª­ã¿è¾¼ã¿
            encodings = self.detect_encoding_comprehensive(file_path)
            df = None
            used_encoding = None

            for encoding in encodings:
                try:
                    print(f"ğŸ“– ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° '{encoding}' ã§èª­ã¿è¾¼ã¿ä¸­...")
                    df = pd.read_csv(file_path, encoding=encoding, dtype=str)
                    used_encoding = encoding
                    print(f"âœ… èª­ã¿è¾¼ã¿æˆåŠŸ: {encoding}")
                    break
                except Exception as e:
                    print(f"âŒ èª­ã¿è¾¼ã¿å¤±æ•—: {encoding} - {str(e)[:50]}")
                    continue

            if df is None:
                raise ValueError("å…¨ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã¿å¤±æ•—")

            # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            df = df.fillna('')

            print(f"\nğŸ“Š CSVæƒ…å ±:")
            print(f"- ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {used_encoding}")
            print(f"- è¡Œæ•°: {len(df)}")
            print(f"- åˆ—æ•°: {len(df.columns)}")
            print(f"- åˆ—å: {list(df.columns)}")

            # æŸ”è»Ÿãªåˆ—ãƒãƒƒãƒ”ãƒ³ã‚°
            column_mapping = self.create_flexible_column_mapping(df.columns)

            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
            if 'material_id' not in column_mapping:
                # æœ€åˆã®åˆ—ã‚’åŸæ–™IDã¨ã—ã¦ä½¿ç”¨
                if len(df.columns) > 0:
                    column_mapping['material_id'] = df.columns[0]
                    print(f"âš ï¸ åŸæ–™IDåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æœ€åˆã®åˆ—ã‚’ä½¿ç”¨: {df.columns[0]}")
                else:
                    raise ValueError("åŸæ–™IDåˆ—ãŒç‰¹å®šã§ãã¾ã›ã‚“")

            results = {
                'success': True,
                'created': 0,
                'updated': 0,
                'skipped': 0,
                'total_rows': len(df),
                'columns': list(df.columns),
                'encoding_used': used_encoding,
                'column_mapping': column_mapping,
                'debug_info': []
            }

            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
            with transaction.atomic():
                for idx, row in df.iterrows():
                    try:
                        # åŸæ–™IDã®å–å¾—ï¼ˆå¿…é ˆï¼‰
                        material_id_col = column_mapping.get('material_id')
                        material_id = self.safe_get_value(row, material_id_col, '').strip()
                        if not material_id:
                            results['skipped'] += 1
                            continue

                        # å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å€¤ã‚’å®‰å…¨ã«å–å¾—
                        material_name_col = column_mapping.get('material_name')
                        material_name = self.safe_get_value(row, material_name_col, f"åŸæ–™_{material_id}")

                        manufacturer_col = column_mapping.get('manufacturer')
                        manufacturer = self.safe_get_value(row, manufacturer_col, '')

                        supplier_col = column_mapping.get('supplier')
                        supplier = self.safe_get_value(row, supplier_col, '')

                        application_col = column_mapping.get('application')
                        application = self.safe_get_value(row, application_col, '')

                        # å‚™è€ƒã®å‡¦ç†ï¼ˆè¤‡æ•°åˆ—ã‹ã‚‰çµåˆã®å¯èƒ½æ€§ï¼‰
                        remarks_parts = []
                        remarks_col = column_mapping.get('remarks')
                        if remarks_col:
                            remark = self.safe_get_value(row, remarks_col, '').strip()
                            if remark:
                                remarks_parts.append(remark)

                        # ä»–ã®å‚™è€ƒé–¢é€£åˆ—ã‚‚æ¢ã™
                        for col in df.columns:
                            if 'å‚™è€ƒ' in str(col) and col != remarks_col:
                                remark = self.safe_get_value(row, col, '').strip()
                                if remark:
                                    remarks_parts.append(f"{col}: {remark}")

                        remarks = '; '.join(remarks_parts)

                        # æ•°å€¤ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å‡¦ç†
                        unit_price_col = column_mapping.get('unit_price')
                        unit_price = self.safe_get_decimal(row, unit_price_col)

                        order_quantity_col = column_mapping.get('order_quantity')
                        if order_quantity_col:
                            order_quantity_str = self.safe_get_value(row, order_quantity_col, '0')
                            order_quantity = self.extract_numeric_from_string(order_quantity_str)
                        else:
                            order_quantity = Decimal('0')

                        # åŸæ–™åŒºåˆ†
                        category_col = column_mapping.get('material_category')
                        material_category = self.safe_get_value(row, category_col, 'Standard')

                        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæœ€åˆã®5è¡Œï¼‰
                        if idx < 5:
                            debug_info = {
                                'row': idx + 1,
                                'material_id': material_id,
                                'material_name': material_name[:30],
                                'manufacturer': manufacturer[:20],
                                'supplier': supplier[:20],
                                'unit_price': str(unit_price),
                                'order_quantity': str(order_quantity),
                                'category': material_category
                            }
                            results['debug_info'].append(debug_info)

                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
                        material, created = Material.objects.get_or_create(
                            material_id=material_id,
                            defaults={
                                'material_name': material_name,
                                'manufacturer': manufacturer,
                                'supplier': supplier,
                                'application': application,
                                'unit_price': unit_price,
                                'order_quantity': order_quantity,
                                'remarks': remarks,
                                'material_category': material_category,
                                'is_active': True
                            }
                        )

                        if created:
                            results['created'] += 1
                        else:
                            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°
                            material.material_name = material_name
                            material.manufacturer = manufacturer
                            material.supplier = supplier
                            material.application = application
                            material.unit_price = unit_price
                            material.order_quantity = order_quantity
                            material.remarks = remarks
                            material.material_category = material_category
                            material.is_active = True
                            material.save()
                            results['updated'] += 1

                    except Exception as e:
                        print(f"âŒ è¡Œ{idx + 1}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                        results['skipped'] += 1
                        continue

            print(f"\nâœ… å‡¦ç†å®Œäº†:")
            print(f"   æ–°è¦ä½œæˆ: {results['created']}ä»¶")
            print(f"   æ›´æ–°: {results['updated']}ä»¶")
            print(f"   ã‚¹ã‚­ãƒƒãƒ—: {results['skipped']}ä»¶")

            return results

        except Exception as e:
            error_msg = f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}"
            print(f"âŒ {error_msg}")
            logger.error(error_msg)
            return {'success': False, 'error': error_msg}

    def safe_get_value(self, row, column_name, default=''):
        """å®‰å…¨ã«å€¤ã‚’å–å¾—"""
        if not column_name or column_name not in row.index:
            return default
        try:
            value = str(row[column_name]).strip()
            return value if value not in ['nan', '', 'None', 'null', 'NaN'] else default
        except:
            return default

    def safe_get_decimal(self, row, column_name):
        """å®‰å…¨ã«æ•°å€¤ã‚’å–å¾—"""
        if not column_name or column_name not in row.index:
            return Decimal('0')
        try:
            value_str = str(row[column_name]).strip()
            if value_str in ['nan', '', 'None', 'null', 'NaN']:
                return Decimal('0')

            # ã‚«ãƒ³ãƒã‚„é€šè²¨è¨˜å·ã‚’é™¤å»
            cleaned = re.sub(r'[^\d.-]', '', value_str)

            if cleaned.count('.') > 1:
                parts = cleaned.split('.')
                cleaned = parts[0] + '.' + ''.join(parts[1:])

            return Decimal(cleaned) if cleaned and cleaned != '-' else Decimal('0')
        except:
            return Decimal('0')

    def extract_numeric_from_string(self, text):
        """æ–‡å­—åˆ—ã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡º"""
        try:
            numbers = re.findall(r'\d+\.?\d*', str(text))
            if numbers:
                return Decimal(numbers[0])
            return Decimal('0')
        except:
            return Decimal('0')

    def analyze_csv_structure(self):
        """CSVæ§‹é€ ã®åˆ†æ"""
        try:
            file_path = os.path.join(self.data_dir, self.csv_file)

            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªï¼ˆä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç¢ºèªï¼‰
            if not os.path.exists(file_path) and os.path.exists(self.data_dir):
                csv_files = [f for f in os.listdir(self.data_dir) if f.endswith('.csv')]
                if csv_files:
                    file_path = os.path.join(self.data_dir, csv_files[0])
                else:
                    return {'error': f'CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.data_dir}'}
            elif not os.path.exists(file_path):
                return {'error': f'CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}'}

            encodings = self.detect_encoding_comprehensive(file_path)
            df = None
            used_encoding = None

            for encoding in encodings:
                try:
                    df = pd.read_csv(file_path, encoding=encoding, dtype=str)
                    used_encoding = encoding
                    break
                except Exception:
                    continue

            if df is None:
                return {'error': 'å…¨ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã¿å¤±æ•—'}

            df = df.fillna('')

            # åˆ—åã®è©³ç´°åˆ†æ
            columns_analysis = {}
            for col in df.columns:
                non_null = df[col].astype(str).str.strip().ne('').sum()
                unique = df[col].nunique()
                samples = df[col].dropna().astype(str).str.strip().head(5).tolist()

                columns_analysis[col] = {
                    'non_null_count': non_null,
                    'unique_count': unique,
                    'sample_values': samples
                }

            # æ¨å¥¨åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°
            column_mapping = self.create_flexible_column_mapping(df.columns)

            return {
                'success': True,
                'encoding': used_encoding,
                'total_rows': len(df),
                'columns': list(df.columns),
                'column_analysis': columns_analysis,
                'recommended_mapping': column_mapping,
                'sample_data': df.head(3).to_dict('records')
            }

        except Exception as e:
            return {'error': f'åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}'}

    def get_csv_summary(self):
        """CSVæ¦‚è¦æƒ…å ±ã®å–å¾—"""
        file_path = os.path.join(self.data_dir, self.csv_file)

        # ä»–ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç¢ºèª
        if not os.path.exists(file_path) and os.path.exists(self.data_dir):
            csv_files = [f for f in os.listdir(self.data_dir) if f.endswith('.csv')]
            if csv_files:
                file_path = os.path.join(self.data_dir, csv_files[0])
            else:
                return {'exists': False, 'error': 'CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}
        elif not os.path.exists(file_path):
            return {'exists': False, 'error': 'CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}

        try:
            stat = os.stat(file_path)
            return {
                'exists': True,
                'file_size': stat.st_size,
                'modified_time': stat.st_mtime,
                'file_name': os.path.basename(file_path)
            }
        except Exception as e:
            return {'exists': True, 'error': str(e)}